{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ee1d7ae-9946-40d2-818b-199d078660c5",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352749e-3c8d-4f03-9916-1080b9835daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd1aee-5cd1-4797-a0e3-6b5aec06c42f",
   "metadata": {},
   "source": [
    "## Sampling Videos from particular video tracks\n",
    "This is done because these video images have feasible object detection and are at considerable distances from the drone other images consists of object that are very very far away from the drone and appear very very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c988cf0-5ead-43f1-8b2c-5a88db8e30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG =====\n",
    "IMG_DIR = r\"D:\\Dataset\\images\\train\"\n",
    "JSON_PATH = \"./dataset/seadronessee/annotations/instances_train_objects_in_water_life_jacket_rm_fixed.json\"\n",
    "DEST_IMG_DIR = \"./dataset/seadronessee_sampled/images/train\"\n",
    "DEST_JSON_PATH = \"./dataset/seadronessee_sampled/annotations/train.json\"\n",
    "TARGET_SIZE_GB = 10  # Stop when ~10GB is reached\n",
    "\n",
    "# Only include these video IDs\n",
    "ALLOWED_VIDEO_IDS = {0, 5, 7, 8, 9, 12, 13, 14, 15, 18, 19, 21}\n",
    "# ==================\n",
    "\n",
    "os.makedirs(DEST_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(DEST_JSON_PATH), exist_ok=True)\n",
    "\n",
    "# Load JSON\n",
    "with open(JSON_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Group images by video_id (only allowed ones)\n",
    "video_images = defaultdict(list)\n",
    "image_id_map = {}\n",
    "\n",
    "for img in data['images']:\n",
    "    if img['video_id'] in ALLOWED_VIDEO_IDS:\n",
    "        video_images[img['video_id']].append(img)\n",
    "        image_id_map[img['id']] = img\n",
    "\n",
    "# Randomize order in each video\n",
    "for vid in video_images:\n",
    "    random.shuffle(video_images[vid])\n",
    "\n",
    "# Start sampling\n",
    "total_bytes = 0\n",
    "selected_images = []\n",
    "selected_image_ids = set()\n",
    "\n",
    "video_ids = sorted(video_images.keys())\n",
    "while total_bytes < TARGET_SIZE_GB * (1024**3) and any(video_images.values()):\n",
    "    for vid in video_ids:\n",
    "        if video_images[vid] and total_bytes < TARGET_SIZE_GB * (1024**3):\n",
    "            img = video_images[vid].pop()  # take one image\n",
    "            src_path = Path(IMG_DIR) / img['file_name']\n",
    "            file_size = src_path.stat().st_size\n",
    "\n",
    "            if total_bytes + file_size > TARGET_SIZE_GB * (1024**3):\n",
    "                break\n",
    "\n",
    "            # Copy image\n",
    "            shutil.copy2(src_path, Path(DEST_IMG_DIR) / img['file_name'])\n",
    "            selected_images.append(img)\n",
    "            selected_image_ids.add(img['id'])\n",
    "            total_bytes += file_size\n",
    "\n",
    "# Filter annotations for selected images\n",
    "selected_annotations = [ann for ann in data['annotations'] if ann['image_id'] in selected_image_ids]\n",
    "\n",
    "# Keep only selected videos\n",
    "selected_video_ids = {img['video_id'] for img in selected_images}\n",
    "selected_videos = [vid for vid in data['videos'] if vid['id'] in selected_video_ids]\n",
    "\n",
    "# Save filtered JSON\n",
    "filtered_data = data.copy()\n",
    "filtered_data['images'] = selected_images\n",
    "filtered_data['annotations'] = selected_annotations\n",
    "filtered_data['videos'] = selected_videos\n",
    "\n",
    "with open(DEST_JSON_PATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)\n",
    "\n",
    "print(f\"âœ… Done! {len(selected_images)} images selected from {len(selected_video_ids)} videos, total size: {total_bytes / (1024**3):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f842e0-e5ba-4568-8896-9e3547f3eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIG =====\n",
    "IMG_DIR = r\"D:\\Dataset\\images\\val\"\n",
    "JSON_PATH = \"./dataset/seadronessee/annotations/instances_val_objects_in_fixed.json\"\n",
    "DEST_IMG_DIR = \"./dataset/seadronessee_sampled/images/val\"\n",
    "DEST_JSON_PATH = \"./dataset/seadronessee_sampled/annotations/val.json\"\n",
    "TARGET_SIZE_GB = 2  # Stop when ~10GB is reached\n",
    "\n",
    "# Only include these video IDs\n",
    "ALLOWED_VIDEO_IDS = {0, 5, 9, 11, 12, 13, 15, 17, 18, 19, 21}\n",
    "# ==================\n",
    "\n",
    "os.makedirs(DEST_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(DEST_JSON_PATH), exist_ok=True)\n",
    "\n",
    "# Load JSON\n",
    "with open(JSON_PATH, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Group images by video_id (only allowed ones)\n",
    "video_images = defaultdict(list)\n",
    "image_id_map = {}\n",
    "\n",
    "for img in data['images']:\n",
    "    if img['video_id'] in ALLOWED_VIDEO_IDS:\n",
    "        video_images[img['video_id']].append(img)\n",
    "        image_id_map[img['id']] = img\n",
    "\n",
    "# Randomize order in each video\n",
    "for vid in video_images:\n",
    "    random.shuffle(video_images[vid])\n",
    "\n",
    "# Start sampling\n",
    "total_bytes = 0\n",
    "selected_images = []\n",
    "selected_image_ids = set()\n",
    "\n",
    "video_ids = sorted(video_images.keys())\n",
    "while total_bytes < TARGET_SIZE_GB * (1024**3) and any(video_images.values()):\n",
    "    for vid in video_ids:\n",
    "        if video_images[vid] and total_bytes < TARGET_SIZE_GB * (1024**3):\n",
    "            img = video_images[vid].pop()  # take one image\n",
    "            src_path = Path(IMG_DIR) / img['file_name']\n",
    "            file_size = src_path.stat().st_size\n",
    "\n",
    "            if total_bytes + file_size > TARGET_SIZE_GB * (1024**3):\n",
    "                break\n",
    "\n",
    "            # Copy image\n",
    "            shutil.copy2(src_path, Path(DEST_IMG_DIR) / img['file_name'])\n",
    "            selected_images.append(img)\n",
    "            selected_image_ids.add(img['id'])\n",
    "            total_bytes += file_size\n",
    "\n",
    "# Filter annotations for selected images\n",
    "selected_annotations = [ann for ann in data['annotations'] if ann['image_id'] in selected_image_ids]\n",
    "\n",
    "# Keep only selected videos\n",
    "selected_video_ids = {img['video_id'] for img in selected_images}\n",
    "selected_videos = [vid for vid in data['videos'] if vid['id'] in selected_video_ids]\n",
    "\n",
    "# Save filtered JSON\n",
    "filtered_data = data.copy()\n",
    "filtered_data['images'] = selected_images\n",
    "filtered_data['annotations'] = selected_annotations\n",
    "filtered_data['videos'] = selected_videos\n",
    "\n",
    "with open(DEST_JSON_PATH, 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)\n",
    "\n",
    "print(f\"âœ… Done! {len(selected_images)} images selected from {len(selected_video_ids)} videos, total size: {total_bytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebd99c-6243-4900-8233-588759799e6b",
   "metadata": {},
   "source": [
    "## Preprocessing the annotation and creating YOLO format annotation\n",
    "The \"swimmer\" and \"swimmer with life jacket\" are merged as \"person\" class to make it easy because in night time using IR footages it will be difficult to distinguish between a \"swimmer\" and a \"swimmer with life jacket\" so that's why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34686200-ac0e-4af3-bcb0-97a3d50b5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_convert_coco_to_yolo(coco_json_path, images_dir, output_labels_dir, output_coco_json_path):\n",
    "    \"\"\"\n",
    "    Merge 'swimmer' and 'swimmers with life jacket' into 'person'\n",
    "    Keep only 'person' and 'boat' categories\n",
    "    Save new COCO JSON and YOLO txt label files\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_labels_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Loading COCO annotations from {coco_json_path}...\")\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco = json.load(f)\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 1: Identify categories\n",
    "    # ==============================================================\n",
    "    merge_classes = [\"swimmer\", \"swimmers with life jacket\"]\n",
    "    merged_class_name = \"person\"\n",
    "    keep_class = \"boat\"\n",
    "    \n",
    "    # Find IDs for the classes weâ€™ll merge\n",
    "    merge_ids = [cat['id'] for cat in coco['categories'] if cat['name'].lower() in merge_classes]\n",
    "    boat_ids = [cat['id'] for cat in coco['categories'] if cat['name'].lower() == keep_class]\n",
    "    \n",
    "    if not merge_ids or not boat_ids:\n",
    "        raise ValueError(\"Could not find 'swimmer'/'swimmers with life jacket' or 'boat' categories in JSON.\")\n",
    "    \n",
    "    print(f\"Merging {merge_classes} into '{merged_class_name}'...\")\n",
    "    \n",
    "    # New category mapping (COCO old id â†’ new id)\n",
    "    # 1 -> person\n",
    "    # 2 -> boat\n",
    "    category_mapping = {}\n",
    "    for cid in merge_ids:\n",
    "        category_mapping[cid] = 1  # person\n",
    "    for cid in boat_ids:\n",
    "        category_mapping[cid] = 2  # boat\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 2: Filter and update annotations\n",
    "    # ==============================================================\n",
    "    new_annotations = []\n",
    "    ann_id = 1\n",
    "    for ann in coco['annotations']:\n",
    "        old_cid = ann['category_id']\n",
    "        if old_cid not in category_mapping:\n",
    "            continue  # skip unwanted classes\n",
    "        \n",
    "        new_ann = ann.copy()\n",
    "        new_ann['category_id'] = category_mapping[old_cid]\n",
    "        new_ann['id'] = ann_id\n",
    "        new_annotations.append(new_ann)\n",
    "        ann_id += 1\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 3: Create new categories list\n",
    "    # ==============================================================\n",
    "    new_categories = [\n",
    "        {\"id\": 1, \"name\": \"person\"},\n",
    "        {\"id\": 2, \"name\": \"boat\"}\n",
    "    ]\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 4: Build new COCO dict and save\n",
    "    # ==============================================================\n",
    "    new_coco = {\n",
    "        \"images\": coco['images'],\n",
    "        \"annotations\": new_annotations,\n",
    "        \"categories\": new_categories\n",
    "    }\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_coco_json_path), exist_ok=True)\n",
    "    with open(output_coco_json_path, 'w') as f:\n",
    "        json.dump(new_coco, f)\n",
    "    \n",
    "    print(f\"âœ… New COCO file saved: {output_coco_json_path}\")\n",
    "    print(f\"   Contains {len(new_annotations)} annotations and 2 categories.\")\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 5: Convert to YOLO txt labels\n",
    "    # ==============================================================\n",
    "    annotations_by_image = {}\n",
    "    for ann in new_annotations:\n",
    "        annotations_by_image.setdefault(ann['image_id'], []).append(ann)\n",
    "    \n",
    "    converted_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for image in coco['images']:\n",
    "        file_name = image['file_name']\n",
    "        width, height = image['width'], image['height']\n",
    "        txt_path = os.path.join(output_labels_dir, Path(file_name).stem + '.txt')\n",
    "        \n",
    "        anns = annotations_by_image.get(image['id'], [])\n",
    "        if not anns:\n",
    "            open(txt_path, 'w').close()\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        yolo_lines = []\n",
    "        for ann in anns:\n",
    "            cat_id = ann['category_id']\n",
    "            class_id = cat_id - 1  # YOLO is 0-indexed: personâ†’0, boatâ†’1\n",
    "            \n",
    "            x, y, w, h = ann['bbox']\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            w /= width\n",
    "            h /= height\n",
    "            \n",
    "            yolo_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "        \n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "        \n",
    "        converted_count += 1\n",
    "    \n",
    "    # ==============================================================\n",
    "    # ðŸŸ¢ Step 6: Save classes.txt\n",
    "    # ==============================================================\n",
    "    with open(os.path.join(output_labels_dir, \"classes.txt\"), 'w') as f:\n",
    "        f.write(\"person\\nboat\\n\")\n",
    "    \n",
    "    print(f\"\\nâœ… Conversion complete!\")\n",
    "    print(f\"Converted: {converted_count} images with annotations\")\n",
    "    print(f\"Skipped: {skipped_count} images without annotations\")\n",
    "    print(f\"Output directory: {output_labels_dir}\")\n",
    "    print(f\"YOLO classes saved to: {os.path.join(output_labels_dir, 'classes.txt')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac378b04-a21f-424a-8a10-aaa3dc362a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Usage Example\n",
    "# ======================================================================\n",
    "\n",
    "train_json = \"./dataset/seadronessee_sampled/annotations/train.json\"\n",
    "val_json = \"./dataset/seadronessee_sampled/annotations/val.json\"\n",
    "\n",
    "train_images = \"./dataset/seadronessee_sampled/images/train/\"\n",
    "val_images = \"./dataset/seadronessee_sampled/images/val/\"\n",
    "\n",
    "train_labels_output = \"./dataset/seadronessee_sampled/labels/train\"\n",
    "val_labels_output = \"./dataset/seadronessee_sampled/labels/val\"\n",
    "\n",
    "train_new_json = \"./dataset/seadronessee_sampled/annotations/train_2cat.json\"\n",
    "val_new_json = \"./dataset/seadronessee_sampled/annotations/val_2cat.json\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Converting TRAIN annotations...\")\n",
    "print(\"=\" * 60)\n",
    "merge_and_convert_coco_to_yolo(train_json, train_images, train_labels_output, train_new_json)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Converting VAL annotations...\")\n",
    "print(\"=\" * 60)\n",
    "merge_and_convert_coco_to_yolo(val_json, val_images, val_labels_output, val_new_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63ce0f-459b-4473-b782-75ae1b6b93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Usage Example\n",
    "# ======================================================================\n",
    "\n",
    "train_json = \"./dataset/seadronessee_sampled/annotations/train.json\"\n",
    "val_json = \"./dataset/seadronessee_sampled/annotations/val.json\"\n",
    "\n",
    "train_images = \"./dataset/seadronessee_sampled/images/train/\"\n",
    "val_images = \"./dataset/seadronessee_sampled/images/val/\"\n",
    "\n",
    "train_labels_output = \"./dataset/seadronessee_sampled/labels/train\"\n",
    "val_labels_output = \"./dataset/seadronessee_sampled/labels/val\"\n",
    "\n",
    "train_new_json = \"./dataset/seadronessee_sampled/annotations/train_2cat.json\"\n",
    "val_new_json = \"./dataset/seadronessee_sampled/annotations/val_2cat.json\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Converting TRAIN annotations...\")\n",
    "print(\"=\" * 60)\n",
    "merge_and_convert_coco_to_yolo(train_json, train_images, train_labels_output, train_new_json)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Converting VAL annotations...\")\n",
    "print(\"=\" * 60)\n",
    "merge_and_convert_coco_to_yolo(val_json, val_images, val_labels_output, val_new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d2210-ce1e-4cc0-b906-ca731c4da2c2",
   "metadata": {},
   "source": [
    "## Converting images from RGBA to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343ff4c6-729f-4489-b956-082b19afa666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All images converted to RGB and saved to: ./dataset/SeaDronesSee_IR_processed/images/train\n"
     ]
    }
   ],
   "source": [
    "# --- Input and Output folders ---\n",
    "input_dir = \"./dataset/SeaDronesSee_IR/images/train/\"\n",
    "output_dir = \"./dataset/SeaDronesSee_IR_processed/images/train\"\n",
    "\n",
    "# --- Create output directory if it doesn't exist ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Loop through all PNG files ---\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".png\"):\n",
    "        input_path = os.path.join(input_dir, file)\n",
    "        output_path = os.path.join(output_dir, file)\n",
    "\n",
    "        # Open, convert, and save to new folder\n",
    "        img = Image.open(input_path).convert(\"RGB\")\n",
    "        img.save(output_path)\n",
    "\n",
    "print(\"âœ… All images converted to RGB and saved to:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69d7f3c-accf-4771-b43a-628337a87505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All images converted to RGB and saved to: ./dataset/SeaDronesSee_IR_processed/images/val\n"
     ]
    }
   ],
   "source": [
    "# --- Input and Output folders ---\n",
    "input_dir = \"./dataset/SeaDronesSee_IR/images/val/\"\n",
    "output_dir = \"./dataset/SeaDronesSee_IR_processed/images/val\"\n",
    "\n",
    "# --- Create output directory if it doesn't exist ---\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Loop through all PNG files ---\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".png\"):\n",
    "        input_path = os.path.join(input_dir, file)\n",
    "        output_path = os.path.join(output_dir, file)\n",
    "\n",
    "        # Open, convert, and save to new folder\n",
    "        img = Image.open(input_path).convert(\"RGB\")\n",
    "        img.save(output_path)\n",
    "\n",
    "print(\"âœ… All images converted to RGB and saved to:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a839e97-795b-4ce1-a137-9da02c76169b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Drone Vision",
   "language": "python",
   "name": "projectdronevision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
