{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08afdb61-6945-4d13-9ef8-c00130d65b93",
   "metadata": {},
   "source": [
    "## Importing Dependencies and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618c06b6-5f76-47cb-8540-c7df041a3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"./model_weights/yolov8m/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a718023-ff04-46af-8b59-6a93d006f945",
   "metadata": {},
   "source": [
    "## Performing inferencing on sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1f3840-c879-4208-8b93-feac4547cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\11351.png: 256x256 5 persons, 3 boats, 307.9ms\n",
      "image 2/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\16231.png: 256x256 2 persons, 4 boats, 271.3ms\n",
      "image 3/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\16913.png: 256x256 2 persons, 3 boats, 342.4ms\n",
      "image 4/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\17466.png: 256x256 3 persons, 3 boats, 303.6ms\n",
      "image 5/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\17861.png: 256x256 6 persons, 1 boat, 280.6ms\n",
      "image 6/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\34104.png: 256x256 1 person, 1 boat, 279.1ms\n",
      "image 7/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\44506.png: 256x256 4 persons, 4 boats, 277.9ms\n",
      "image 8/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\47168.png: 256x256 4 persons, 1 boat, 280.8ms\n",
      "image 9/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\49864.png: 256x256 2 persons, 2 boats, 275.7ms\n",
      "image 10/10 C:\\Users\\Lenovo-Z50-70\\Desktop\\IEEE Conference Project\\dataset\\sample_inference_data\\49891.png: 256x256 3 persons, 2 boats, 331.0ms\n",
      "Speed: 2.6ms preprocess, 295.0ms inference, 2.1ms postprocess per image at shape (1, 3, 256, 256)\n",
      "✅ Saved: custom_predictions/11351.png\n",
      "✅ Saved: custom_predictions/16231.png\n",
      "✅ Saved: custom_predictions/16913.png\n",
      "✅ Saved: custom_predictions/17466.png\n",
      "✅ Saved: custom_predictions/17861.png\n",
      "✅ Saved: custom_predictions/34104.png\n",
      "✅ Saved: custom_predictions/44506.png\n",
      "✅ Saved: custom_predictions/47168.png\n",
      "✅ Saved: custom_predictions/49864.png\n",
      "✅ Saved: custom_predictions/49891.png\n"
     ]
    }
   ],
   "source": [
    "# Run inference but don't save annotated images automatically\n",
    "results = model.predict(\n",
    "    source=\"./dataset/sample_inference_data/\",\n",
    "    save=False,  # We'll save manually\n",
    "    conf=0.25,\n",
    "    iou=0.45\n",
    ")\n",
    "\n",
    "# Output directory for custom visualization\n",
    "os.makedirs(\"custom_predictions\", exist_ok=True)\n",
    "\n",
    "# Loop through all results\n",
    "for i, result in enumerate(results):\n",
    "    img = result.orig_img.copy()\n",
    "    \n",
    "    # Get detections\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()\n",
    "    classes = result.boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    # Assign a unique color per class\n",
    "    COLORS = {\n",
    "        0: (0, 255, 0),   # person -> green\n",
    "        1: (255, 0, 0),   # boat -> blue\n",
    "    }\n",
    "    \n",
    "    # Draw bounding boxes (no label text)\n",
    "    for box, cls in zip(boxes, classes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        color = COLORS.get(cls, (255, 255, 255))\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 1)  # thickness=1 for thinner box\n",
    "\n",
    "    # Save result\n",
    "    save_path = f\"custom_predictions/{os.path.basename(result.path)}\"\n",
    "    cv2.imwrite(save_path, img)\n",
    "    print(f\"✅ Saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916c5cf-696b-47ee-841a-5ab9bbb61a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Drone Vision",
   "language": "python",
   "name": "projectdronevision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
